# ğŸ  Rug Prompt Generator

A Next.js application for processing large rug inventory CSV files and generating AI-styled room scene images using Google Gemini Batch API.

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Next.js](https://img.shields.io/badge/Next.js-16+-black)
![TypeScript](https://img.shields.io/badge/TypeScript-5+-blue)

## âœ¨ Features

- **ğŸ“¤ CSV Upload & Processing** - Drag-and-drop support for rug inventory files
- **ğŸ”„ Automated Pipeline** - Process 5000+ rugs automatically with parallel batch processing
- **ğŸ–¼ï¸ Image-to-Image Generation** - Transform rug images into styled room scenes
- **ğŸ“¦ Smart Chunking** - Split large CSVs into optimal chunks (75 rugs each)
- **â¸ï¸ Pause/Resume** - Full control over long-running batch jobs
- **ğŸ“Š Real-time Progress** - Visual tracking of all chunks and batches
- **ğŸ’° Cost Efficient** - Uses Gemini Batch API at 50% discount

## ğŸš€ Quick Start

### 1. Clone & Install

\`\`\`bash
git clone <your-repo>
cd rugapp
npm install
\`\`\`

### 2. Configure Environment

\`\`\`bash
cp .env.example .env.local
\`\`\`

Edit \`.env.local\`:
\`\`\`env
GOOGLE_GENERATIVE_AI_API_KEY=your_gemini_api_key_here
\`\`\`

> Get your API key at [Google AI Studio](https://aistudio.google.com/apikey)

### 3. Run Development Server

\`\`\`bash
npm run dev
\`\`\`

Open [http://localhost:3000](http://localhost:3000)

## ğŸ“– Usage

### Option 1: Automated Pipeline (Recommended for 5000+ rugs)

1. Click **"ğŸš€ Automated Pipeline"** mode
2. Upload your CSV file
3. Click **"â–¶ï¸ Start Pipeline"**
4. Watch as the system automatically:
   - Splits into ~75 rug chunks
   - Processes 5 chunks in parallel
   - Downloads images & generates JSONL
   - Submits to Gemini Batch API
   - Waits for results, then continues

### Option 2: Manual Processing

1. Click **"Manual Processing"** mode
2. Upload CSV â†’ Generate Batch â†’ Submit to Gemini
3. Monitor status and download results

### Option 3: Split CSV Only

1. Click **"Split CSV Only"** mode
2. Upload large CSV
3. Download individual chunks for external processing

## ğŸ“ CSV Format

Your CSV should include these columns:

| Column | Description | Example |
|--------|-------------|---------|
| \`SKU\` | Product identifier | \`RUG-12345\` |
| \`Title\` | Rug name | \`Persian Silk Carpet\` |
| \`Primary Category\` | Main category | \`Persian\`, \`Modern\` |
| \`Material\` | Rug material | \`Wool\`, \`Silk\` |
| \`Size\` / \`exactSize\` | Dimensions | \`8x10\`, \`9'6" x 13'6"\` |
| \`image link\` | URL to rug image | \`https://...\` |
| \`fieldColor\` | Main color | \`Red\`, \`Blue\` |
| \`borderColor\` | Border color | \`Gold\`, \`Ivory\` |
| \`Style\` | Design style | \`Traditional\`, \`Modern\` |

See \`docs/sample-rugs.csv\` for a complete example.

## ğŸ—ï¸ Architecture

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Frontend (React)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ CSV Upload  â”‚ â”‚  Pipeline   â”‚ â”‚   Log Viewer     â”‚  â”‚
â”‚  â”‚  Dropzone   â”‚ â”‚  Controls   â”‚ â”‚   (Real-time)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API Routes                            â”‚
â”‚  /api/upload      /api/process-chunk    /api/batch-statusâ”‚
â”‚  /api/chunk-csv   /api/submit-batch     /api/download-*  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Google Gemini API                       â”‚
â”‚           (Batch API - 50% cost discount)               â”‚
â”‚         gemini-2.5-flash-image model                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

## ğŸ“‚ Project Structure

\`\`\`
rugapp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ page.tsx              # Main page
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚       â”œâ”€â”€ upload/           # CSV upload & processing
â”‚   â”‚       â”œâ”€â”€ chunk-csv/        # Split large CSVs
â”‚   â”‚       â”œâ”€â”€ process-chunk/    # Process single chunk
â”‚   â”‚       â”œâ”€â”€ generate-batch/   # Generate JSONL
â”‚   â”‚       â”œâ”€â”€ submit-batch/     # Submit to Gemini
â”‚   â”‚       â”œâ”€â”€ batch-status/     # Check batch status
â”‚   â”‚       â””â”€â”€ download-*/       # Download results
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ rug-processor-app.tsx # Main app component
â”‚   â”‚   â”œâ”€â”€ AutomatedPipeline.tsx # Pipeline UI
â”‚   â”‚   â””â”€â”€ LogViewer.tsx         # Real-time logs
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”œâ”€â”€ csv-processor.ts      # CSV parsing
â”‚   â”‚   â”œâ”€â”€ gemini-service.ts     # Gemini API client
â”‚   â”‚   â”œâ”€â”€ batch-pipeline.ts     # Pipeline logic
â”‚   â”‚   â”œâ”€â”€ rug-utils.ts          # Prompt generation
â”‚   â”‚   â””â”€â”€ logger.ts             # Logging system
â”‚   â””â”€â”€ types/
â”‚       â””â”€â”€ rug.ts                # TypeScript types
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ sample-rugs.csv           # Sample data
â”‚   â””â”€â”€ gemini-batch-api.md       # API documentation
â””â”€â”€ README.md
\`\`\`

## âš™ï¸ Configuration

### Chunk Size Recommendations

| Scenario | Chunk Size | Reason |
|----------|------------|--------|
| With images | 75 | ~50-75MB per batch |
| Text only | 300-500 | Lightweight requests |
| Testing | 10-20 | Quick iteration |

### Pipeline Settings

\`\`\`typescript
// In AutomatedPipeline component
chunkSize = 75         // Rugs per chunk
concurrentLimit = 5    // Parallel batches
pollingInterval = 15s  // Status check frequency
\`\`\`

## ğŸ’° Cost Estimation

Using Gemini Batch API (50% discount):

| Rugs | Estimated Cost | Time |
|------|---------------|------|
| 100 | ~\$0.15 | ~5 min |
| 1,000 | ~\$1.50 | ~30 min |
| 5,500 | ~\$8.25 | ~3-4 hours |

*Estimates based on ~\$0.0015 per rug with image processing*

## ğŸ› ï¸ API Routes

| Endpoint | Method | Description |
|----------|--------|-------------|
| \`/api/upload\` | POST | Upload & parse CSV |
| \`/api/chunk-csv\` | POST | Split CSV into chunks |
| \`/api/process-chunk\` | POST | Process single chunk (images + JSONL + submit) |
| \`/api/generate-batch\` | POST | Generate JSONL batch file |
| \`/api/submit-batch\` | POST | Submit batch to Gemini |
| \`/api/batch-status\` | GET | Check batch job status |
| \`/api/download-results\` | GET | Download batch results |
| \`/api/extract-images\` | POST | Extract images from results |

## ğŸ§ª Development

\`\`\`bash
# Run development server
npm run dev

# Build for production
npm run build

# Run production server
npm start

# Lint code
npm run lint
\`\`\`

## ğŸš€ Deployment

### Vercel (Recommended)

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new)

Add environment variable:
- \`GOOGLE_GENERATIVE_AI_API_KEY\`

## ï¿½ï¿½ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Submit a pull request

---

Built with â¤ï¸ using Next.js, TypeScript, and Google Gemini AI
